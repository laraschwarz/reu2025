{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.155-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting deep-sort-realtime\n",
      "  Using cached deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (2.0.2)\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics)\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from ultralytics) (11.2.1)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from ultralytics) (2.32.4)\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from ultralytics) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from ultralytics) (0.15.2)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pandas>=1.1.4 (from ultralytics)\n",
      "  Using cached pandas-2.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached fonttools-4.58.4-cp39-cp39-macosx_10_9_universal2.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.23.0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
      "Requirement already satisfied: filelock in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
      "Requirement already satisfied: sympy in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Using cached ultralytics-8.3.155-py3-none-any.whl (1.0 MB)\n",
      "Using cached deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
      "Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.4-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached pandas-2.3.0-cp39-cp39-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pytz, py-cpuinfo, tzdata, tqdm, scipy, pyyaml, pyparsing, opencv-python, kiwisolver, importlib-resources, fonttools, cycler, contourpy, pandas, matplotlib, deep-sort-realtime, ultralytics-thop, ultralytics\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [ultralytics]\u001b[0m [ultralytics]sources]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.0 cycler-0.12.1 deep-sort-realtime-1.3.2 fonttools-4.58.4 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 opencv-python-4.11.0.86 pandas-2.3.0 py-cpuinfo-9.0.0 pyparsing-3.2.3 pytz-2025.2 pyyaml-6.0.2 scipy-1.13.1 tqdm-4.67.1 tzdata-2025.2 ultralytics-8.3.155 ultralytics-thop-2.0.14\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /private/var/folders/8f/35n42rtj25n3wqr91nxnc05r0000gn/T/pip-req-build-gt1evffi\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /private/var/folders/8f/35n42rtj25n3wqr91nxnc05r0000gn/T/pip-req-build-gt1evffi\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ftfy (from clip==1.0)\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from clip==1.0) (25.0)\n",
      "Collecting regex (from clip==1.0)\n",
      "  Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from clip==1.0) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from clip==1.0) (0.15.2)\n",
      "Requirement already satisfied: wcwidth in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch->clip==1.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch->clip==1.0) (4.14.0)\n",
      "Requirement already satisfied: sympy in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch->clip==1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch->clip==1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torch->clip==1.0) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torchvision->clip==1.0) (2.0.2)\n",
      "Requirement already satisfied: requests in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torchvision->clip==1.0) (2.32.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from torchvision->clip==1.0) (11.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/laraschwarz/miniconda3/envs/deepsort2/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (2025.6.15)\n",
      "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
      "Building wheels for collected packages: clip\n",
      "\u001b[33m  DEPRECATION: Building 'clip' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'clip'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369549 sha256=e472297ad9cb1c0c87b2f114ba6da110b812c092a17928177ce6d0e47cb46811\n",
      "  Stored in directory: /private/var/folders/8f/35n42rtj25n3wqr91nxnc05r0000gn/T/pip-ephem-wheel-cache-6eympnpg/wheels/c8/e4/e1/11374c111387672fc2068dfbe0d4b424cb9cdd1b2e184a71b5\n",
      "Successfully built clip\n",
      "Installing collected packages: regex, ftfy, clip\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [clip]\n",
      "\u001b[1A\u001b[2KSuccessfully installed clip-1.0 ftfy-6.3.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics deep-sort-realtime opencv-python numpy\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "<class 'torch.torch_version.TorchVersion'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(type(torch.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.4\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)  # Should print: 1.24.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution: 1920 x 1080\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('/Users/laraschwarz/Code/reu2025/deepSORT2/trimmedFrance.mp4')  # Replace with your video path\n",
    "\n",
    "if cap.isOpened():\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f\"Resolution: {width} x {height}\")\n",
    "else:\n",
    "    print(\"Failed to open video.\")\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepsort(path, output='output.mp4', target_classes=None):\n",
    "    # Initialize YOLOv10 model\n",
    "    model = YOLO('yolov5l.pt')  # Choose your model\n",
    "\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Create output directory if not exists\n",
    "    os.makedirs(\"output_videos\", exist_ok=True)\n",
    "    output_path = f\"output_videos/{output}\"\n",
    "\n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Initialize DeepSort tracker\n",
    "    tracker = DeepSort(\n",
    "        max_age=20,\n",
    "        n_init=2,\n",
    "        embedder='clip_ViT-B/16',\n",
    "        half=False,\n",
    "        embedder_gpu=False\n",
    "    )\n",
    "    \n",
    "    # Create color palette for IDs\n",
    "    color_palette = {}\n",
    "    \n",
    "    # Set default target classes (person, car, truck) if none provided\n",
    "    if target_classes is None:\n",
    "        target_classes = [0, 2, 7]  # COCO class IDs: 0=person, 2=car, 7=truck\n",
    "\n",
    "    frame_count = 0\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Run YOLOv10 detection\n",
    "            results = model(frame, verbose=False)[0]\n",
    "            \n",
    "            # Convert detections to DeepSort format\n",
    "            detections = []\n",
    "            for box in results.boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                conf = float(box.conf[0])\n",
    "                cls_id = int(box.cls[0])\n",
    "                \n",
    "                # Filter by target classes\n",
    "                if cls_id in target_classes:\n",
    "                    detections.append(([x1, y1, x2-x1, y2-y1], conf, cls_id))\n",
    "            \n",
    "            # Update tracker\n",
    "            tracks = tracker.update_tracks(detections, frame=frame)\n",
    "            \n",
    "            # Draw tracking results\n",
    "            for track in tracks:\n",
    "                if not track.is_confirmed():\n",
    "                    continue\n",
    "                    \n",
    "                track_id = track.track_id\n",
    "                ltrb = track.to_ltrb()\n",
    "                x1, y1, x2, y2 = map(int, ltrb)\n",
    "                \n",
    "                # Generate unique color for each ID\n",
    "                if track_id not in color_palette:\n",
    "                    # Generate random but distinct color\n",
    "                    color_palette[track_id] = (\n",
    "                        random.randint(50, 200),\n",
    "                        random.randint(50, 200),\n",
    "                        random.randint(50, 200)\n",
    "                    )\n",
    "                color = color_palette[track_id]\n",
    "                \n",
    "                # Draw thicker bounding box (4px instead of 2)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 4)\n",
    "                \n",
    "                # Create white background for ID text\n",
    "                text = f\"ID:{track_id}\"\n",
    "                text_scale = 1.5  # Increased from 0.7 (3x larger)\n",
    "                text_thickness = 4\n",
    "                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                           text_scale, text_thickness)[0]\n",
    "                \n",
    "                # Position background above bounding box\n",
    "                bg_x1 = x1\n",
    "                bg_y1 = max(0, y1 - text_size[1] - 10)  # Ensure within frame\n",
    "                bg_x2 = x1 + text_size[0] + 5\n",
    "                bg_y2 = y1 - 10\n",
    "                \n",
    "                # Draw background if it's within frame boundaries\n",
    "                if bg_y1 >= 0 and bg_y2 < frame_height and bg_x2 < frame_width:\n",
    "                    cv2.rectangle(frame, \n",
    "                                 (bg_x1, bg_y1),\n",
    "                                 (bg_x2, bg_y2),\n",
    "                                 (255, 255, 255), -1)  # White background\n",
    "                \n",
    "                    # Display ID with same color as bounding box\n",
    "                    cv2.putText(frame, text, (x1, y1 - 15), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, text_scale, color, \n",
    "                               text_thickness)\n",
    "            \n",
    "            # Write frame to video file\n",
    "            out.write(frame)\n",
    "            \n",
    "            # Print progress\n",
    "            frame_count += 1\n",
    "            if frame_count % 50 == 0:\n",
    "                print(f\"Processed {frame_count} frames\")\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted by user\")\n",
    "    finally:\n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(f\"Video saved to: {output_path}\")\n",
    "        print(f\"Total frames processed: {frame_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP 💡 Replace 'model=yolov5l.pt' with new 'model=yolov5lu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5lu.pt to 'yolov5lu.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102M/102M [00:06<00:00, 16.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 frames\n",
      "Processed 100 frames\n",
      "Processed 150 frames\n",
      "Processed 200 frames\n",
      "Processed 250 frames\n",
      "Processed 300 frames\n",
      "Processed 350 frames\n",
      "Processed 400 frames\n",
      "Processed 450 frames\n",
      "Processed 500 frames\n",
      "Processed 550 frames\n",
      "Processed 600 frames\n",
      "Video saved to: output_videos/output7.mp4\n",
      "Total frames processed: 615\n"
     ]
    }
   ],
   "source": [
    "deepsort('/Users/laraschwarz/Code/reu2025/deepSORT2/trimmedFrance.mp4', output='output7.mp4', target_classes= [0,1,2,3,5,6,7])  # Adjust input video path and target classes as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepsort2)",
   "language": "python",
   "name": "deepsort2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
